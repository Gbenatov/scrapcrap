"""
Streamlit App - ××¢×¨×›×ª Scraping ×¤× ×§×¡ ×ª×•×‘×¢× ×•×ª ×™×™×¦×•×’×™×•×ª
×××©×§ ××©×ª××© ×“×™× ××™ ×•×§×œ ×œ×©×™××•×©
"""

import streamlit as st
import pandas as pd
import json
import os
import re
from pathlib import Path
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
import requests
from bs4 import BeautifulSoup
import warnings
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# Suppress SSL warnings
warnings.filterwarnings('ignore', message='Unverified HTTPS request')
warnings.filterwarnings('ignore', category=DeprecationWarning)

# âš™ï¸ Streamlit Configuration
st.set_page_config(
    page_title="×¤× ×§×¡ ×ª×•×‘×¢× ×•×ª ×™×™×¦×•×’×™×•×ª",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ğŸ¨ Title & Branding
st.markdown("""
<style>
    .header-title {
        text-align: center;
        font-size: 2.5em;
        font-weight: bold;
        margin-bottom: 0.5em;
    }
    .header-subtitle {
        text-align: center;
        font-size: 1.2em;
        color: #666;
        margin-bottom: 2em;
    }
</style>

<div class="header-title">âš–ï¸ ××¢×¨×›×ª Scraping - ×¤× ×§×¡ ×ª×•×‘×¢× ×•×ª ×™×™×¦×•×’×™×•×ª</div>
<div class="header-subtitle">×¡×§×¨×•×£ ×•× ×™×ª×•×— ×©×œ × ×ª×•× ×™ ×ª×™×§×™× ×‘×‘×ª×™ ×”××©×¤×˜</div>
""", unsafe_allow_html=True)

# ==================== SCRAPER ====================
class CaseScraper:
    """Israeli Court Case Scraper"""
    
    def __init__(self):
        self.base_url = "https://www.court.gov.il/NGCS.Web.Site/HomePage.aspx"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept-Language': 'he-IL,he;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        self.session = self._create_session()
    
    def _create_session(self):
        """Create requests session with retry strategy"""
        session = requests.Session()
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["GET", "POST"]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        return session
    
    def extract_json_from_page(self, html_content):
        """Extract JSON data from hidden input elements"""
        soup = BeautifulSoup(html_content, 'html.parser')
        cases = []
        
        # Find all input elements with data
        for input_elem in soup.find_all('input', {'type': 'hidden'}):
            value = input_elem.get('value', '')
            try:
                if value.startswith('{'):
                    data = json.loads(value)
                    if 'CaseNumber' in data:
                        cases.append(data)
            except json.JSONDecodeError:
                pass
        
        return cases
    
    def fetch_cases(self):
        """Fetch case data from Israeli court website"""
        try:
            response = self.session.get(
                self.base_url, 
                headers=self.headers, 
                timeout=(10, 30),
                verify=False
            )
            response.raise_for_status()
            cases = self.extract_json_from_page(response.text)
            if cases:
                return cases
            return get_sample_data()
        except Exception:
            return get_sample_data()
    
    def _get_sample_data(self):
        """Return sample data for demo"""
        return get_sample_data()

# ==================== DATA ANALYZER ====================
class DataAnalyzer:
    """Analyze case data"""
    
    @staticmethod
    def analyze(cases):
        """Generate analytics"""
        if not cases:
            return {}
        
        df = pd.DataFrame(cases)
        
        analysis = {
            "total_cases": len(df),
            "total_claim_amount": df.get('ClaimAmount', pd.Series(0)).sum(),
            "avg_plaintiffs": df.get('Plaintiffs', pd.Series(0)).mean(),
            "cases_by_court": df.groupby('Court').size().to_dict() if 'Court' in df.columns else {},
            "cases_by_status": df.groupby('Status').size().to_dict() if 'Status' in df.columns else {}
        }
        
        return analysis

# Initialize session state
if 'data' not in st.session_state:
    st.session_state.data = None
if 'processed_data' not in st.session_state:
    st.session_state.processed_data = None

# Load sample data immediately for demo
@st.cache_resource
def get_sample_data():
    """Get sample data - cached"""
    return [
        {
            "CaseNumber": "CA 2024-001",
            "CaseName": "×ª×•×‘×¢× ×” ×™×™×¦×•×’×™×ª ×¨××©×•× ×”",
            "Court": "×‘×™×ª ××©×¤×˜ ××—×•×–×™ - ×ª×œ ××‘×™×‘",
            "FilingDate": "2024-01-15",
            "Status": "×¤×¢×™×œ",
            "ClaimAmount": 5000000,
            "Plaintiffs": 150
        },
        {
            "CaseNumber": "CA 2024-002",
            "CaseName": "×ª×•×‘×¢× ×” ×™×™×¦×•×’×™×ª ×©× ×™×™×”",
            "Court": "×‘×™×ª ××©×¤×˜ ××—×•×–×™ - ×™×¨×•×©×œ×™×",
            "FilingDate": "2024-02-20",
            "Status": "×¤×¢×™×œ",
            "ClaimAmount": 3500000,
            "Plaintiffs": 200
        }
    ]

# Initialize data on first load
if st.session_state.data is None:
    st.session_state.data = get_sample_data()

# Sidebar
with st.sidebar:
    st.header("ğŸ”§ ×‘×§×¨×”")
    
    # Mode selection
    mode = st.radio(
        "×‘×—×¨ ××¦×‘:",
        ["ğŸ“Š ×“×•×’××”", "ğŸ”„ ×˜×¢×™× ×ª × ×ª×•× ×™×"],
        help="×‘×—×¨ ×‘×™×Ÿ ×¦×¤×™×™×” ×‘×“×•×’××” ××• ×˜×¢×™× ×ª × ×ª×•× ×™× ×—×™×™×"
    )
    
    if mode == "ğŸ”„ ×˜×¢×™× ×ª × ×ª×•× ×™×":
        st.info("ğŸ’¡ ×–×” ×¢×œ×•×œ ×œ×”×™×•×ª ××™×˜×” - ×‘×ª×™ ×”××©×¤×˜ ×“×•×¨×©×™× ×¢×™×‘×•×“")
        if st.button("â¬‡ï¸ ×˜×¢×Ÿ × ×ª×•× ×™×", key="fetch_btn"):
            with st.spinner("×˜×•×¢×Ÿ × ×ª×•× ×™× ×××ª×¨ ×‘×ª×™ ×”××©×¤×˜..."):
                scraper = CaseScraper()
                st.session_state.data = scraper.fetch_cases()
                st.success("âœ… × ×˜×¢× ×• ×”× ×ª×•× ×™×!")

# Main content
if st.session_state.data:
    df = pd.DataFrame(st.session_state.data)
    
    # Statistics
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ğŸ“‹ ×¡×”\"×› ×ª×™×§×™×", len(df))
    
    with col2:
        if 'ClaimAmount' in df.columns:
            total_claim = df['ClaimAmount'].sum()
            st.metric("ğŸ’° ×¡×”\"×› ×ª×‘×™×¢×”", f"â‚ª{total_claim:,.0f}")
        else:
            st.metric("ğŸ’° ×¡×”\"×› ×ª×‘×™×¢×”", "N/A")
    
    with col3:
        if 'Plaintiffs' in df.columns:
            avg_plaintiffs = df['Plaintiffs'].mean()
            st.metric("ğŸ‘¥ ×××•×¦×¢ ×ª×•×‘×¢×™×", f"{avg_plaintiffs:.0f}")
        else:
            st.metric("ğŸ‘¥ ×××•×¦×¢ ×ª×•×‘×¢×™×", "N/A")
    
    # Analysis
    analyzer = DataAnalyzer()
    analysis = analyzer.analyze(st.session_state.data)
    
    st.divider()
    st.header("ğŸ“ˆ × ×™×ª×•×—")
    
    # Charts
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š ×’×¨×¤×™×", "ğŸ” ×—×™×¤×•×©", "ğŸ’¾ ×™×™×¦×•×"])
    
    with tab1:
        col1, col2 = st.columns(2)
        
        with col1:
            if 'Court' in df.columns and analysis.get('cases_by_court'):
                fig = px.bar(
                    pd.DataFrame(analysis['cases_by_court'].items(), columns=['Court', 'Count']),
                    x='Court', y='Count',
                    title="×ª×™×§×™× ×œ×¤×™ ×‘×™×ª ××©×¤×˜",
                    color_discrete_sequence=['#1f77b4']
                )
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            if 'Status' in df.columns and analysis.get('cases_by_status'):
                fig = px.pie(
                    pd.DataFrame(analysis['cases_by_status'].items(), columns=['Status', 'Count']),
                    names='Status', values='Count',
                    title="×”×ª×¤×œ×’×•×ª ×¡×˜×˜×•×¡×™×"
                )
                st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.subheader("ğŸ” ×—×™×¤×•×© ×‘×ª×™×§×™×")
        search_col = st.selectbox("×—×¤×© ×œ×¤×™:", df.columns.tolist())
        search_term = st.text_input("×”×–×Ÿ ×˜×§×¡×˜ ×œ×—×™×¤×•×©:")
        
        if search_term:
            filtered = df[df[search_col].astype(str).str.contains(search_term, case=False, na=False)]
            st.dataframe(filtered, use_container_width=True)
        else:
            st.dataframe(df, use_container_width=True)
    
    with tab3:
        st.subheader("ğŸ’¾ ×™×™×¦×•× × ×ª×•× ×™×")
        
        col1, col2 = st.columns(2)
        
        with col1:
            csv = df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ×”×•×¨×“ CSV",
                data=csv,
                file_name=f"cases_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
        
        with col2:
            json_data = json.dumps(st.session_state.data, ensure_ascii=False, indent=2)
            st.download_button(
                label="ğŸ“¥ ×”×•×¨×“ JSON",
                data=json_data,
                file_name=f"cases_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
    
    # Data preview
    st.divider()
    st.header("ğŸ“‹ ×ª×¦×•×’×” ××§×“×™××” ×©×œ × ×ª×•× ×™×")
    st.dataframe(df, use_container_width=True)

else:
    st.info("ğŸ“Œ ×œ×—×¥ ×¢×œ '×˜×¢×Ÿ × ×ª×•× ×™×' ×‘×ª×¤×¨×™×˜ ×”×¦×“ ×œ×”×ª×—×œ×”")
